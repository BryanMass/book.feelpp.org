= Data Management

This document details how files are retrieved and produced within {feelpp}.
The section <<_description, Description>> will details the {feelpp} input
and output data generated.
The different file formats are detailed in section <<_types_of_data,Types Of Data>>.
The different data storage tools are detailed in section <<_data_in_feel, Data
in {feelpp}>>.

== Description

=== Geometry and Mesh

To run a simulation, {feelpp} needs to works with different input datasets.
{feelpp} can use either a geometry file issued from CAD/CAD or directly
a mesh file. A geometry/mesh file represents the domain of the study and is
a requirement.

NOTE: The mesh file can have potentially a big size!

=== Fields

A field file represent a function defined on a mesh, which is associated to FunctionSpace concept.
This files can be used in many context : restart a simulation, defined an initial solution from another simulation, post-processing,

=== Configuration files

Configuration files are required to setup the simulation : mesh files, physical model, solution strategy, post-processing, ...

NOTE: In particular, it indicates where the data are located.

=== Visualization

During the simulation, {feelpp} produces data outputs that can be visualize
with post-processing software and exported in different formats.


NOTE: Depending on the application, the outputs can have a big size!

=== Database

{feelpp} can produce several kind of databases, dependings of the context (e.g. Certified Reduced Basis, POD).
Once generated, these database can be stored on a distant server or saved statically via DB dump.

//But also in the benchmark system (See <<_benchmark,Benchmark>>  section for details).
//These database are stored on a distant server or can be saved statically via DB dump.

=== Logging

A logging system monitor the execution of the simulation. This logging system
helps to determine the reason why the application might have failed.
The logs are saved.

=== Benchmark

Reproducibility is an important and difficult challenge. When all data are
available (inputs/ouputs), reproducing existing simulation results for
verification or validation purpose means to be able to place the simulation in
the same original conditions (same user environment, parametrization,
hardware). Often the only information available are the one described in
papers. For example, reader have access to tables, plots and parameters 
precised in results descriptions which may be incomplete. 
From the author point of view, the difficulty is to know what should or should
not be presented in the paper so that user may be able to reproduce the paper 
main result.

Feel++ introduces a benchmark system to help users first, to better catch and
store crucial information of their applications (problem size, hardware, ...),
but also to be able to compare new simulation results based on existing and
validated one.

We distinguish currently several parts that will interact with storage:

1. <<_journal, The journal system>>
2. <<_checker_system, The checker system>>
3. <<_testing_system, The testing system (ctest)>>

==== Journal

The principle of the {feelpp} journal is to retrieve the simulation information
all gathered in a unique metadata file. 
Two storage approach can be considered and are detailed hereafter.

===== Static file (JSON)

A journal file is generated at the end of the simulation or at intermediate
moments based on user event (step updates).

NOTE: The journal is different from the main logging system and 
serve two different purpose.

By default, these metadata are stored in a unique JSON files (`journal.json`).
This file is stored as part of the output and can be used to make queries.
The journal file is versioned to guaranty comparison metadata compatibility
between two simulation.

===== Database (MongoDB)

{feelpp} can use link:https://www.mongodb.com/fr/[mongodb], a NOSQL database
(weak dependency). Each generated journal file represent an entry of the mongodb
database.

==== Checker system

The checker system permits to check some metrics in order to know whether the
simulation has finished successfully or not. For example, different norms can
be verified for a set of parameters. This system needs to access a
specific and known database (see <<database_mongodb, Database (MongoDB)>> section).
For example to compute convergence curves or simply verify the result match a
previous exact same simulation.

NOTE: This system works in conjonction with the journal system.

==== Testing system

{feelpp} deploys its applications as containers for different dedicated softwares
(docker, singularity). These applications are tested to ensure they are working.
The testing system is based on CTest.
Some test applications may be use checker, thus required (local/online) database
access.

=== Documentation

Most {feelpp} documentation is generated using the asiidoc format.
link:https://antora.org/[Antora] is used to generated the documention
link:docs.feelpp.org[]. The man pages are automatically generated in the same
format and details each application usage.
The documentation is automatically generated and stored on an specific web server.

== Types of data

The following table summarize the type of data used and generated in {feelpp}:

.{feelpp} type of file
[options="header"]
|===
| Type | format(s)

| <<_geometry_and_mesh,CAO files>>
| .geo , .step 

| <<_geometry_and_mesh,Mesh files>>
| HDF5+JSON, all read by GMSH

| <<_fields,Fields files>>
| HDF5, Boost serialization

| <<_configuration_files,Configuration files>>
| CFG, JSON 

| <<_visualization,Visualization files>>
| Ensight, Ensight Gold, VTK, VTK.js, CSV

| <<_journal,Journal files>>
| JSON

| <<_database,{feelpp} database>>
| HDF5+JSON, Boost serialization, mongodb dump

| <<_documentation, Documentation files>>
| .adoc, .png, .jpeg, ...


|===


== Data storage

We use two kind of storage, it depends of the type of data.
Mesh files, visualization files and simulation journal files are store in the Girder plateform, the others one in the Github repository.

=== Girder plateform

Girder is a free and open source web-based data management platform developed by Kitware as part of the Resonant data and analytics ecosystem.
It is a complete back-end (server side) technology that can be used with other applications via its RESTful API, or it can be used via its own front-end (client side web pages and JavaScript).

==== Data organisation

Data can be stored for a particular user or in the concept of collections.
This concept allow to share the data between one or several users (Groups concept).

Data are organized in hierarchical structure with Folders and Files.
When Folders or Files are defined, an unique ID is attributed at this entities.
These IDs allow to access easily to the data.

A levels of permission can be define for a ressource :

* READ permission (can view and download resources)
* WRITE permission (includes READ permission, can edit the properties of a resource)

Collections and folder can defined with attributes :

* Public (meaning viewable even by anonymous users)
* Private (meaning viewable only by those with READ access).

==== Upload/Download data

* REST API
* Web interface
* Girder CLI
* Python Client
* JavaScript libraries

==== Authentication

=== MongoDB

Several MongoDB database are used as storage. MongoDB storage
can be seen in two ways:

* static (stored local as a file, or local server)
* server (stored on external mongodb server)


=== Github repository

The access to the github file can be done by :

* using raw.githubusercontent.com
* REST API


== Data in Feel++ 

=== Simulations

==== Input data

The inputs require for run a Feel++ simulation are :

* the CAO or the mesh files
* one or several cfg files
* one or several json files

These files are given to the application by specifying :

* each file separately 
* a directory containing each file
* a zip file containing each file

If the data are not available locally, they can be retrieve remotely by specifying :

** Girder : file or folder ID
** Github : relative path in the github repository

==== Output data

The simulation will produce some datas:

* Visualization file
* Journal file

:leveloffset: +4

include::benchmark.adoc[]

:leveloffset: -4


=== Pre-Processing

The mesh generation or the mesh partitioning can be a step expensive in time.
We recommand to prepare these kind of data before to run the simulation.

The mesh is built from a CAO file, the partitioning from the mesh file generated.

The mesh (eventually the partitionning) is uploaded to the grider plateform

=== Post-Processing

After the simulation terminated, datas as vtk.js or screenshot of the visualisation can be produce through python scripts.
This datas can be uploaded to the Girder plateform.


== Visualization

=== Paraview

ParaView is an open-source, multi-platform data analysis and visualization application.

The data must be available locally.
  
=== Paraview-Web

ParaViewWeb, the JavaScript library, is a Web framework to build applications with interactive scientific visualization inside the Web browser. Those applications can leverage a VTK and/or ParaView backend for large data processing and rendering, but can also be used on a static Web server like Apache or NGINX. You can even build local command line tools and use your browser to interact with your application.

The data must be available locally on the server side (where the ParaView server is launch).

=== vtk.js

vtk.js is a rendering library made for Scientific Visualization on the Web. It adapts the VTK structure and expertise to bring high performance rendering into your browser.

The data can be available locally or on the web. We can directly give Girder url of ressource for example.

== Documentations
